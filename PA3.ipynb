{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from numpy.linalg import norm\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tackle the task of classifying by topic posts made in six different internet newsgroups –\n",
    "comp.windows.x, rec.sport.baseball, sci.med, misc.forsale, talk.politics.mideast and talk.religion.misc – that\n",
    "correspond to labels 1, . . . , 6 respectively.\n",
    "\n",
    "Each line of the training or test set is a feature vector of length 819, followed by a label (1, . . . , 6).\n",
    "The first line in the dictionary is the word\n",
    "that corresponds to the first coordinate, the second line to the second coordinate, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean the txt files and seperate the labels from the actual vectors\n",
    "def clean_txt(path):\n",
    "    f = open(path,'r')\n",
    "    arr = (f.read()).split(\"\\n\")\n",
    "    arr = arr[:-1]\n",
    "    labels = []\n",
    "    for vector in arr:\n",
    "        labels.append(int(vector[-1]))\n",
    "    vectors = []\n",
    "    for vector in arr:\n",
    "        vectors.append(vector.split(' '))\n",
    "    for i in range(len(vectors)):\n",
    "        vectors[i] = list(map(int,vectors[i][:-1]))\n",
    "    return np.array(vectors),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors,test_labels = clean_txt(\"pa3test.txt\")\n",
    "train_vectors,train_labels = clean_txt(\"pa3train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  3, ...,  0,  0,  0],\n",
       "       [ 0,  0, 45, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  1, ...,  0,  0,  0],\n",
       "       [ 0,  0,  4, ...,  0,  0,  0],\n",
       "       [ 0,  0,  4, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds indeces of vectors with labels either 1 or 2 in the train vectors\n",
    "df1_train = pd.DataFrame(np.loadtxt(\"pa3train.txt\"))\n",
    "subset_train_df = df1_train[df1_train[819].isin([1.0,2.0])]\n",
    "subset_train_index = subset_train_df.index\n",
    "# Gets subset of train vectors with labels of 1 or 2\n",
    "subset_train_vectors = []\n",
    "subset_train_labels = np.array([])\n",
    "for i in subset_train_index:\n",
    "    subset_train_vectors.append(train_vectors[i])\n",
    "    subset_train_labels = np.append(subset_train_labels, train_labels[i])\n",
    "subset_train_vectors = np.array(subset_train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds indeces of vectors with labels either 1 or 2 in the test vectors\n",
    "df1_test = pd.DataFrame(np.loadtxt(\"pa3test.txt\"))\n",
    "subset_test_df = df1_test[df1_test[819].isin([1.0,2.0])]\n",
    "subset_test_index = subset_test_df.index\n",
    "# Gets subset of test vectors with labels of 1 or 2\n",
    "subset_test_vectors = []\n",
    "subset_test_labels = np.array([])\n",
    "for i in subset_test_index:\n",
    "    subset_test_vectors.append(test_vectors[i])\n",
    "    subset_test_labels = np.append(subset_test_labels, test_labels[i])\n",
    "subset_test_vectors = np.array(subset_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch from 2 to -1 \n",
    "subset_train_labels[subset_train_labels == 2] = -1\n",
    "subset_test_labels[subset_test_labels == 2] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Perceptron Algorithm\n",
    "\n",
    "def perceptron(data, labels, iterations):\n",
    "    w = np.array([0]*819)\n",
    "    j = 0\n",
    "    while j != iterations:\n",
    "        for i in range(len(labels)):\n",
    "            y = labels[i]\n",
    "            x = data[i]\n",
    "            if y * np.dot(w,x) <= 0:\n",
    "                w = w + (y*x)\n",
    "            else:\n",
    "                w = w\n",
    "        j +=1\n",
    "    return w\n",
    "w = perceptron(subset_train_vectors,subset_train_labels,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error after 1 iteration = 0.04128440366972477\n"
     ]
    }
   ],
   "source": [
    "#Tested against train data for 1 iteration\n",
    "predicted_labels = [np.dot(subset_train_vectors[i] , w) for i in range(len(subset_train_labels))]\n",
    "train_error_1iter = train_error_1iter = np.mean(np.sign(predicted_labels) != subset_train_labels)\n",
    "print(\"Train error after 1 iteration = \" + str(train_error_1iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat perceptron algo for 2,3,4 passes on test and train data\n",
    "iterations = [2,3,4]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for j in iterations:\n",
    "    train_w = perceptron(subset_train_vectors,subset_train_labels,j)\n",
    "    test_w = perceptron(subset_test_vectors, subset_test_labels,j)\n",
    "    \n",
    "    predicted_train_labels = [np.dot(subset_train_vectors[i] , train_w) for i in range(len(subset_train_labels))]\n",
    "    predicted_test_labels = [np.dot(subset_test_vectors[i] , train_w) for i in range(len(subset_test_labels))]\n",
    "    \n",
    "    train_error = train_error_1iter = np.mean(np.sign(predicted_train_labels) != subset_train_labels)\n",
    "    test_error = test_error_1iter = np.mean(np.sign(predicted_test_labels) != subset_test_labels)\n",
    "    \n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainError</th>\n",
       "      <th>TestError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040367</td>\n",
       "      <td>0.061008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021101</td>\n",
       "      <td>0.045093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019266</td>\n",
       "      <td>0.047745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrainError  TestError\n",
       "2    0.040367   0.061008\n",
       "3    0.021101   0.045093\n",
       "4    0.019266   0.047745"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'TrainError':train_errors,'TestError':test_errors}, index = iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a linear classification algorithm using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "def perceptron2(data, labels, iterations):\n",
    "    w = np.array([0]*819)\n",
    "    j = 0\n",
    "    while j != iterations:\n",
    "        phrase = 0\n",
    "        for i in range(len(labels)):\n",
    "            y = labels[i]\n",
    "            x = data[i]\n",
    "            phrase += (y*x)/(1 + np.exp(y * np.dot(w,x)))\n",
    "        w = w + learning_rate * phrase\n",
    "        j +=1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w,x):\n",
    "    return 1 / (1 + np.exp(-np.dot(w,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error after 2 iterations = 0.4944954128440367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-0a3198a846ac>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-np.dot(w,x)))\n"
     ]
    }
   ],
   "source": [
    "w2 =perceptron2(subset_train_vectors, subset_train_labels,2)\n",
    "\n",
    "predicted_labels2 = np.array([sigmoid(w2,subset_train_vectors[i]) for i in range(len(subset_train_labels))])\n",
    "predicted_labels2[predicted_labels2 >= 0.5] = 1\n",
    "predicted_labels2[predicted_labels2 < 0.5] = -1\n",
    "\n",
    "train_error_2iter = np.mean(predicted_labels2 != subset_train_labels)\n",
    "print(\"Train error after 2 iterations = \" + str(train_error_2iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-440d77184328>:10: RuntimeWarning: overflow encountered in exp\n",
      "  phrase += (y*x)/(1 + np.exp(y * np.dot(w,x)))\n",
      "<ipython-input-14-0a3198a846ac>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-np.dot(w,x)))\n"
     ]
    }
   ],
   "source": [
    "#Repeat perceptron2 algo for 10,50,100 passes on test and train data\n",
    "iterations = [10,50,100]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for j in iterations:\n",
    "    train_w = perceptron2(subset_train_vectors,subset_train_labels,j)\n",
    "    test_w = perceptron2(subset_test_vectors, subset_test_labels,j)\n",
    "    \n",
    "    predicted_train_labels = np.array([sigmoid(train_w,subset_train_vectors[i]) for i in range(len(subset_train_labels))])\n",
    "    predicted_test_labels = np.array([sigmoid(train_w,subset_test_vectors[i]) for i in range(len(subset_test_labels))])\n",
    "    \n",
    "    predicted_train_labels[predicted_train_labels >= 0.5] = 1\n",
    "    predicted_train_labels[predicted_train_labels < 0.5] = -1\n",
    "    predicted_test_labels[predicted_test_labels >= 0.5] = 1\n",
    "    predicted_test_labels[predicted_test_labels < 0.5] = -1\n",
    "    \n",
    "    train_error = np.mean(predicted_train_labels != subset_train_labels)\n",
    "    test_error = np.mean(predicted_test_labels != subset_test_labels)\n",
    "    \n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainError</th>\n",
       "      <th>TestError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.294495</td>\n",
       "      <td>0.297082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.061008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.017431</td>\n",
       "      <td>0.045093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TrainError  TestError\n",
       "10     0.294495   0.297082\n",
       "50     0.036697   0.061008\n",
       "100    0.017431   0.045093"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'TrainError':train_errors,'TestError':test_errors}, index = iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three coordinates in w with the highest and lowest values. These are the words that are most positively and negatively correlated, from the dictionary text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = str(open('pa3dictionary.txt').read()).split(' \\n')[:-1]\n",
    "w3 = perceptron(subset_train_vectors,subset_train_labels,3)\n",
    "pd3 = pd.DataFrame({\"Values\":w3,\"Words\":words})\n",
    "smallest = pd3.sort_values('Values',ascending = True).head(3)\n",
    "largest = pd3.sort_values('Values',ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-72.0</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>-43.0</td>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-40.0</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Values Words\n",
       "78    -72.0    he\n",
       "469   -43.0  team\n",
       "393   -40.0  game"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>130.0</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>77.0</td>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>46.0</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Values    Words\n",
       "438   130.0     file\n",
       "466    77.0  program\n",
       "203    46.0     line"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same as above but done on the logistic regression implementation of the linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-440d77184328>:10: RuntimeWarning: overflow encountered in exp\n",
      "  phrase += (y*x)/(1 + np.exp(y * np.dot(w,x)))\n"
     ]
    }
   ],
   "source": [
    "w4 = perceptron2(subset_train_vectors,subset_train_labels,50)\n",
    "pd4 = pd.DataFrame({\"Values\":w4,\"Words\":words})\n",
    "smallest4 = pd4.sort_values('Values',ascending = True).head(3)\n",
    "largest4 = pd4.sort_values('Values',ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-5.053053</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-2.313363</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-2.182689</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Values Words\n",
       "78  -5.053053    he\n",
       "393 -2.313363  game\n",
       "58  -2.182689  they"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>3.042452</td>\n",
       "      <td>window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2.090256</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.049261</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Values   Words\n",
       "617  3.042452  window\n",
       "438  2.090256    file\n",
       "72   2.049261     use"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs-all multi-class classifier with a Don’t Know Option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly modified perceptron\n",
    "def perceptron5(data, labels, iterations,i):\n",
    "    w = np.array([0]*819)\n",
    "    j = 0\n",
    "    while j != iterations:\n",
    "        for index in range(len(labels)):\n",
    "            y = labels[index]\n",
    "            x = data[index]\n",
    "            if y != i:\n",
    "                y = -1\n",
    "            else:\n",
    "                y = 1\n",
    "            if y * np.dot(w,x) <= 0:\n",
    "                w = w + (y*x)\n",
    "            else:\n",
    "                w = w\n",
    "        j +=1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(arr):\n",
    "    arr = list(arr)\n",
    "    if arr.count(1) == 1:\n",
    "        return arr.index(1) + 1\n",
    "    return 'Dont Know'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making classifiers 1....6\n",
    "classifiers = []\n",
    "for i in range(1,7):\n",
    "    classifiers.append(perceptron5(train_vectors,train_labels,1,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting labels\n",
    "predicted_labels5 = []\n",
    "for x in test_vectors:\n",
    "    arr = np.sign(np.dot(classifiers,x))\n",
    "    predicted_labels5.append(labeler(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating conf_matrix\n",
    "temp = confusion_matrix(list(map(str,predicted_labels5)), list(map(str,test_labels)))\n",
    "conf_matrix = []\n",
    "for row in temp:\n",
    "    conf_matrix.append(list(row[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[133, 1, 6, 4, 0, 0],\n",
       " [2, 126, 6, 5, 2, 2],\n",
       " [0, 3, 65, 0, 0, 3],\n",
       " [3, 1, 0, 127, 0, 0],\n",
       " [3, 6, 13, 1, 125, 13],\n",
       " [1, 2, 6, 0, 11, 53],\n",
       " [43, 53, 79, 47, 18, 37]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding sums of each columns to calculate total # of examples with label j\n",
    "col_sums = [0]*6\n",
    "for i in range(6):\n",
    "    for row in conf_matrix:\n",
    "        col_sums[i] += row[i]\n",
    "\n",
    "# Dividing every element in each column by the col_sum of that column \n",
    "# This finds # of examples with label i classified as j\n",
    "for i in range(7):\n",
    "    for j in range(6):\n",
    "        curr_value = conf_matrix[i][j] \n",
    "        conf_matrix[i][j] = curr_value / col_sums[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71891892 0.00520833 0.03428571 0.02173913 0.         0.        ]\n",
      " [0.01081081 0.65625    0.03428571 0.02717391 0.01282051 0.01851852]\n",
      " [0.         0.015625   0.37142857 0.         0.         0.02777778]\n",
      " [0.01621622 0.00520833 0.         0.69021739 0.         0.        ]\n",
      " [0.01621622 0.03125    0.07428571 0.00543478 0.80128205 0.12037037]\n",
      " [0.00540541 0.01041667 0.03428571 0.         0.07051282 0.49074074]\n",
      " [0.23243243 0.27604167 0.45142857 0.25543478 0.11538462 0.34259259]]\n"
     ]
    }
   ],
   "source": [
    "#converting confusion matrix back to arr or arrays\n",
    "print(np.array(list(map(np.array,conf_matrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy for each i \n",
    "row_sums = []\n",
    "i = 0\n",
    "for j in range(6):\n",
    "    row_sums.append(sum(conf_matrix[j]) - conf_matrix[j][i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06123317805383022,\n",
       " 0.1036094694790346,\n",
       " 0.04340277777777779,\n",
       " 0.021424549549549532,\n",
       " 0.2475570834809966,\n",
       " 0.12062060687060688]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: i = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b: i = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c: [6][6] with a value of 0.12037037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
